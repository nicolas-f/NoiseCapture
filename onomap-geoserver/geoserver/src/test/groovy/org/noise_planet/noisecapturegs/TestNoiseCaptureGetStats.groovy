/*
 * This file is part of the NoiseCapture application and OnoMap system.
 *
 * The 'OnoMaP' system is led by Lab-STICC and Ifsttar and generates noise maps via
 * citizen-contributed noise data.
 *
 * This application is co-funded by the ENERGIC-OD Project (European Network for
 * Redistributing Geospatial Information to user Communities - Open Data). ENERGIC-OD
 * (http://www.energic-od.eu/) is partially funded under the ICT Policy Support Programme (ICT
 * PSP) as part of the Competitiveness and Innovation Framework Programme by the European
 * Community. The application work is also supported by the French geographic portal GEOPAL of the
 * Pays de la Loire region (http://www.geopal.org).
 *
 * Copyright (C) 2007-2016 - IFSTTAR - LAE
 * Lab-STICC â€“ CNRS UMR 6285 Equipe DECIDE Vannes
 *
 * NoiseCapture is a free software; you can redistribute it and/or modify it under the terms of the
 * GNU General Public License as published by the Free Software Foundation; either version 3 of
 * the License, or(at your option) any later version. NoiseCapture is distributed in the hope that
 * it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
 * more details.You should have received a copy of the GNU General Public License along with this
 * program; if not, write to the Free Software Foundation,Inc., 51 Franklin Street, Fifth Floor,
 * Boston, MA 02110-1301  USA or see For more information,  write to Ifsttar,
 * 14-20 Boulevard Newton Cite Descartes, Champs sur Marne F-77447 Marne la Vallee Cedex 2 FRANCE
 *  or write to scientific.computing@ifsttar.fr
 */

package org.noise_planet.noisecapturegs

import groovy.json.JsonSlurper
import groovy.sql.Sql
import org.h2.Driver
import org.junit.After
import org.junit.BeforeClass
import org.junit.Ignore
import org.junit.Rule
import org.junit.rules.TemporaryFolder

import java.sql.Connection
import java.sql.Statement
import java.time.Instant
import java.time.ZoneId
import java.time.format.DateTimeFormatter
import java.util.zip.ZipInputStream

/**
 * Test parsing of zip file using H2GIS database
 */
class TestNoiseCaptureGetStats extends GroovyTestCase {
    static Connection connection;


    @Rule
    public static TemporaryFolder folder= new TemporaryFolder(new File("build"));

    @BeforeClass
    void setUp() {
        folder.create()
        connection = Driver.load().connect("jdbc:h2:"+new File(folder.newFolder(),"test;USER=sa;MODE=PostgreSQL").getAbsolutePath(), null)
        Statement st = connection.createStatement()
        // Init spatial
        st.execute("CREATE ALIAS IF NOT EXISTS H2GIS_EXTENSION FOR \"org.h2gis.ext.H2GISExtension.load\";\n" +
                "CALL H2GIS_EXTENSION();")
        // Init schema
        st.execute(new File(TestNoiseCaptureGetStats.class.getResource("inith2.sql").getFile()).text)
        // Load timezone file
        st.execute("CALL FILE_TABLE('"+TestNoiseCaptureProcess.getResource("tz_world.shp").file+"', 'TZ_WORLD');")
        st.execute("CREATE SPATIAL INDEX ON TZ_WORLD(THE_GEOM)")
        // ut_deps has been derived from https://www.data.gouv.fr/fr/datasets/contours-des-departements-francais-issus-d-openstreetmap/ (c) osm
        // See ut_deps.txt for more details
        st.execute("CALL GEOJSONREAD('"+TestNoiseCaptureProcess.getResource("ut_deps.geojson").file+"', 'GADM28');")
    }

    @After
    void tearDown() {
        connection.close();
        folder.delete()
    }

    @Ignore
    static
    def addTestRecord(sql, time, location, levels) {
        Map record = [track_uuid         : UUID.randomUUID().toString(),
                      pk_user            : 1,
                      version_number     : 14,
                      record_utc         : time,
                      pleasantness       : 50,
                      device_product     : "NC",
                      device_model       : "NC",
                      device_manufacturer: "NC",
                      noise_level        : 10 * Math.log10(levels.sum({Math.pow(10.0, it / 10.0)})),
                      time_length        : levels.size(),
                      gain_calibration   : 0]
        sql.executeInsert("INSERT INTO noisecapture_user(user_uuid, date_creation) VALUES (:uuid, cast(cast(:userdate as timestamptz) as date))", [uuid: UUID.randomUUID(), userdate : time])
        def recordId = sql.executeInsert("INSERT INTO noisecapture_track(track_uuid, pk_user, version_number, record_utc," +
                " pleasantness, device_product, device_model, device_manufacturer, noise_level, time_length, gain_calibration) VALUES (" +
                ":track_uuid, :pk_user, :version_number, :record_utc, :pleasantness, :device_product, :device_model," +
                " :device_manufacturer, :noise_level, :time_length, :gain_calibration)", record)[0][0] as Integer
        // Add 3 points
        for(float level : levels) {
            def fields = [the_geom     : location,
                          pk_track     : recordId,
                          noise_level  : level,
                          speed        : 0,
                          accuracy     : 4,
                          orientation  : 120,
                          time_date    : time,
                          time_location: time]
            def ptId = sql.executeInsert("INSERT INTO noisecapture_point(the_geom, pk_track, noise_level, speed," +
                    " accuracy, orientation, time_date, time_location) VALUES (ST_GEOMFROMTEXT(:the_geom, 4326)," +
                    " :pk_track, :noise_level, :speed, :accuracy, :orientation, :time_date, :time_location)", fields)[0][0] as Integer
        }
        // Push track into process queue
        Map processQueue = [pk_track: recordId]
        sql.executeInsert("INSERT INTO NOISECAPTURE_PROCESS_QUEUE VALUES (:pk_track)", processQueue)
    }

    void testTracksExport() {
        Sql.LOG.level = java.util.logging.Level.SEVERE
        Sql sql = new Sql(connection)
        addTestRecord(sql, new nc_parse().epochToRFCTime(System.currentTimeMillis()), "POINT(2.4710 44.2772)", [70, 75, 72])
        addTestRecord(sql, new nc_parse().epochToRFCTime(System.currentTimeMillis()- (1000 * 3600 * 24 * 8)) , "POINT(13.1853 43.0961)", [60, 61, 58])
        addTestRecord(sql, new nc_parse().epochToRFCTime(System.currentTimeMillis()- (1000 * 3600 * 24 * 16)) , "POINT(9.0038 42.2513)", [65, 68, 64])
        // Compute stats
        def stats = new nc_get_stats().getStatistics(connection)
        assertEquals(1, stats["week_new_contributors"])
        assertEquals(1, stats["week_new_tracks_count"])
        assertEquals("France", stats["countries"].names[0])
        assertEquals(2, stats["countries"].total_tracks[0])
        assertEquals("Italy", stats["countries"].names[1])
        assertEquals(1, stats["countries"].total_tracks[1])

        assertEquals("France", stats["week_tracks"]["datasets"][0].label)
        assertEquals(6, stats["week_tracks"]["datasets"][0].data.sum())

        assertEquals("Italy",stats["week_tracks"]["datasets"][1].label)
        assertEquals(3, stats["week_tracks"]["datasets"][1].data.sum())
    }

}
